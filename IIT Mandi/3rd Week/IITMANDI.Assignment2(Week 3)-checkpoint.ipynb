{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#imported the dataset given to us\n",
    "pid=pd.read_csv(\"C:\\\\Users\\\\Micontroller Lab N16\\\\IIT MANDI\\\\3rd Week\\\\pima-indians-diabetes.csv\",sep=',')\n",
    "\n",
    "#made a copy of the original dataset\n",
    "pid1=pid.copy()\n",
    "print(pid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid.columns\n",
    "#created a list of all the columns present in the dataset\n",
    "pid_col=list(pid.columns)\n",
    "pid2=pid.copy()                 #made a copy of original dataset without attribute class\n",
    "pid_col\n",
    "pid_col1=pid_col.copy()      #we do not want to bring changes in the class column so we removed it from the copied dataset\n",
    "pid_col1.remove('class')\n",
    "pid2.drop([\"class\"], axis = 1, inplace = True)\n",
    "print(pid_col1)\n",
    "print('\\n\\n')\n",
    "print(pid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pid2                  # X denotes the input functions and here class defines whether the person is ill or not\n",
    "print(X1)\n",
    "y1 = pid['class']                  #y denotes the output functions\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split       #As given we are assigning 70% of data for training and 30% for testing\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, train_size = 0.7,random_state = 42)\n",
    "\n",
    "print(X1_train)\n",
    "print(y1_train)\n",
    "print(X1_test)\n",
    "print(y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "neighbors=[1,3,5,7,9,11,13,15,17,19,21]\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "acc=[]\n",
    "  \n",
    "# Loop over K values\n",
    "for i, k in enumerate(neighbors):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X1_train, y1_train)\n",
    "    print('Predicted Outcomes for neighbours =',k,'are', knn.predict(X1_test))\n",
    "    print('\\n')\n",
    "    \n",
    "    print('Accuracy = ',knn.score(X1_test, y1_test))\n",
    "    if ((knn.score(X1_test, y1_test))>=0):\n",
    "        acc.append(knn.score(X1_test, y1_test))\n",
    "    print('\\n')\n",
    "   \n",
    "    matrix = confusion_matrix(y1_test,knn.predict(X1_test))\n",
    "    print('Confusion Matrix = ',matrix)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "      \n",
    "    # Compute traning and test data accuracy\n",
    "    train_accuracy[i] = knn.score(X1_train, y1_train)\n",
    "    test_accuracy[i] = knn.score(X1_test, y1_test)\n",
    "\n",
    "print(acc)\n",
    "print('\\n')\n",
    "print('maximum accuracy is =', max(acc)*100)\n",
    "\n",
    "  \n",
    "# Generate plot\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing dataset Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training dataset Accuracy')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = pid2                  # X denotes the input functions and here class defines whether the person is ill or not\n",
    "print(X1)\n",
    "y2 = pid['class']                  #y denotes the output functions\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split       #As given we are assigning 70% of data for training and 30% for testing\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, train_size = 0.7,random_state = 42)\n",
    "\n",
    "print(X2_train)\n",
    "print(y2_train)\n",
    "print(X2_test)\n",
    "print(y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GaussianNB()\n",
    "model.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X2_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y2_test, y_pred)*100\n",
    "print('accuracy = ',accuracy,'%')\n",
    "print('\\n')\n",
    "matrix=confusion_matrix(y2_test,y_pred)\n",
    "print('Confusion Matrix = ',matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common way of speeding up a machine learning algorithm is by using Principal Component Analysis (PCA). \n",
    "If your learning algorithm is too slow because the input dimension is too high, then using PCA to speed it up can be a reasonable choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = pid2                  # X denotes the input functions and here class defines whether the person is ill or not\n",
    "print(X1)\n",
    "y3 = pid['class']                  #y denotes the output functions\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split       #As given we are assigning 70% of data for training and 30% for testing\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, train_size = 0.7,random_state = 42)\n",
    "\n",
    "print(X3_train)\n",
    "print('\\n\\n')\n",
    "print(y3_train)\n",
    "print('\\n\\n')\n",
    "print(X3_test)\n",
    "print('\\n\\n')\n",
    "print(y3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(X3_train)\n",
    "print(X3_train)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X3_train = scaler.transform(X3_train)   #expecting 2D array so only X values can be passed\n",
    "X3_test = scaler.transform(X3_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "#the code has .95 for the number of components parameter. It means that scikit-learn choose the minimum number of principal components such that 95% of the variance is retained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     #number of components PCA choose after fitting the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Make an instance of the Model\n",
    "dimension = [0.25,0.40,0.60,0.70,0.80,0.90,0.95,0.99]\n",
    "accu=[]\n",
    "for z in enumerate(dimension):\n",
    "    \n",
    "    pca = PCA(z) \n",
    "\n",
    "    pca.fit(X3_train)\n",
    "    pca.n_components_ \n",
    "\n",
    "    X3_train = pca.transform(X3_train)\n",
    "    X3_test= pca.transform(X3_test)\n",
    "\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "    neighbors=[1,3,5,7,9,11,13,15,17,19,21]\n",
    "    train_accuracy = np.empty(len(neighbors))\n",
    "    test_accuracy = np.empty(len(neighbors))\n",
    "    acc=[]\n",
    "\n",
    "    # Loop over K values\n",
    "    for i, k in enumerate(neighbors):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X3_train, y3_train)\n",
    "        print('Predicted Outcomes for neighbours =',k,'are', knn.predict(X3_test))\n",
    "        print('\\n')\n",
    "\n",
    "        print('Accuracy = ',knn.score(X3_test, y3_test))\n",
    "        if ((knn.score(X3_test, y3_test))>=0):\n",
    "            acc.append(knn.score(X3_test, y3_test)) \n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "        matrix = confusion_matrix(y3_test,knn.predict(X3_test))\n",
    "        print('Confusion Matrix = ',matrix)\n",
    "        print('\\n\\n')\n",
    "\n",
    "\n",
    "        # Compute traning and test data accuracy\n",
    "        train_accuracy[i] = knn.score(X3_train, y3_train)\n",
    "        test_accuracy[i] = knn.score(X3_test, y3_test)\n",
    "\n",
    "    print(acc)\n",
    "    print('\\n')\n",
    "    print('maximum accuracy is =', max(acc)*100)\n",
    "\n",
    "  \n",
    "# Generate plot\n",
    "#plt.plot(neighbors, test_accuracy, label = 'Testing dataset Accuracy')\n",
    "#plt.plot(neighbors, train_accuracy, label = 'Training dataset Accuracy')\n",
    "\n",
    "\n",
    "#plt.legend()\n",
    "#plt.xlabel('n_neighbors')\n",
    "#plt.ylabel('Accuracy')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
